{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7660880e-6c91-40e3-b2a0-534053ac219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 0. IMPORT LIBRARIES\n",
    "# ==================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, mean_absolute_error, mean_squared_error,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4247c8c-89d7-466e-a5a8-7a63ee251b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape: (135136, 24)\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# 1. LOAD DATASET\n",
    "# ==================================================\n",
    "file_path = r\"E:\\WOU_BITS INTERN\\39 BUS SYSTEM\\39 BUS SYSTEM FAULT.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Original Dataset Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b71bfef-f846-445b-af37-8002bc9f6745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset Shape (Only 1_39): (4004, 24)\n",
      "Available Fault Lines: ['1_39']\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# 2. FILTER ONLY FAULT LINE 1_39\n",
    "# ==================================================\n",
    "df = df[df[\"Fault Line\"] == \"1_39\"].copy()\n",
    "\n",
    "print(\"Filtered Dataset Shape (Only 1_39):\", df.shape)\n",
    "print(\"Available Fault Lines:\", df[\"Fault Line\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db042adf-5c89-47d5-99a7-f6ecbeb355e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 3. DEFINE FEATURES AND LABELS\n",
    "# ==================================================\n",
    "FEATURES = [\n",
    "    \"Phase Voltage A/Terminal in kV\",\n",
    "    \"Phase Voltage B/Terminal in kV\",\n",
    "    \"Phase Voltage C/Terminal in kV\",\n",
    "    \"Phase Current A/Terminal in kA\",\n",
    "    \"Phase Current B/Terminal in kA\",\n",
    "    \"Phase Current C/Terminal in kA\",\n",
    "    \"Terminal/Bus\"\n",
    "]\n",
    "\n",
    "# ðŸ”¥ Removed \"Fault Line\" because it is fixed now\n",
    "LABELS = [\n",
    "    \"Fault Location\",\n",
    "    \"Primary\",\n",
    "    \"CCT\",\n",
    "    \"B1\"\n",
    "]\n",
    "\n",
    "X = df[FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9186eb19-e368-489b-8715-f55925c29199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 4. FEATURE SCALING\n",
    "# ==================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad5cbf3-2f69-4030-9a40-0947c517a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 5. FINAL RESULT STORAGE\n",
    "# ==================================================\n",
    "final_summary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0308275a-2f4d-47b7-92e9-331e6c7e5660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸŽ¯ LABEL: Fault Location\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ LABEL: Primary\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ LABEL: CCT\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ LABEL: B1\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# 6. LOOP FOR EACH LABEL\n",
    "# ==================================================\n",
    "for label in LABELS:\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"ðŸŽ¯ LABEL: {label}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    y = LabelEncoder().fit_transform(df[label])\n",
    "    n_classes = len(np.unique(y))\n",
    "\n",
    "    if n_classes < 2:\n",
    "        print(\"âŒ Only one class present â€” skipped\")\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y,\n",
    "        test_size=0.25,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71b62901-f258-4179-a1da-de89658b4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ==================================================\n",
    "    # 7. RANDOM FOREST\n",
    "    # ==================================================\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_prob = rf.predict_proba(X_test)\n",
    "    rf_pred = np.argmax(rf_prob, axis=1)\n",
    "\n",
    "    acc_rf = accuracy_score(y_test, rf_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3de39b44-da3a-40ca-885c-2d2a2dc24ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ojash\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [01:36:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# XGBOOST (Binary Classification Version)\n",
    "# ==================================================\n",
    "\n",
    "if len(np.unique(y_train)) < 2:\n",
    "    print(\"âš ï¸ XGBoost skipped â€” only one class in training split\")\n",
    "    acc_xgb = 0\n",
    "    xgb_prob = None\n",
    "    xgb_pred = None\n",
    "else:\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"binary:logistic\",   # âœ… Binary objective\n",
    "        eval_metric=\"logloss\",\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    xgb_prob = xgb.predict_proba(X_test)\n",
    "\n",
    "    acc_xgb = accuracy_score(y_test, xgb_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7d5446a-ff54-4612-a2fc-eb91f80a2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ==================================================\n",
    "    # ENSEMBLE (Auto Alpha Search)\n",
    "    # ==================================================\n",
    "    best_alpha = 0\n",
    "    best_acc = 0\n",
    "    best_pred = None\n",
    "    best_prob = None\n",
    "\n",
    "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
    "        ens_prob = alpha * rf_prob + (1 - alpha) * xgb_prob\n",
    "        ens_pred = np.argmax(ens_prob, axis=1)\n",
    "        acc = accuracy_score(y_test, ens_pred) * 100\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_alpha = alpha\n",
    "            best_pred = ens_pred\n",
    "            best_prob = ens_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "851a3b3c-1f80-44b0-8596-eab45767c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ==================================================\n",
    "    # 10. MODEL SELECTION\n",
    "    # ==================================================\n",
    "    scores = {\n",
    "        \"Random Forest\": acc_rf,\n",
    "        \"XGBoost\": acc_xgb,\n",
    "        \"RF + XGB Ensemble\": best_ens_acc\n",
    "    }\n",
    "\n",
    "    best_model = max(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "552182c7-cf29-43af-97f4-e19c93700337",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ==================================================\n",
    "    # FINAL METRICS\n",
    "    # ==================================================\n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    prec = precision_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    rec = recall_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\") * 100\n",
    "    except:\n",
    "        roc_auc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb518763-63e5-4054-a2e3-60ef6fdcd971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy       : 100.00%\n",
      "XGB Accuracy      : 100.00%\n",
      "Ensemble Accuracy : 100.00% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 100.00%\n",
      "Precision : 100.00%\n",
      "Recall    : 100.00%\n",
      "F1-score  : 100.00%\n",
      "ROC-AUC : Not defined\n",
      "MAE       : 0.0000\n",
      "MSE       : 0.0000\n",
      "RMSE      : 0.0000\n"
     ]
    }
   ],
   "source": [
    "    # ==================================================\n",
    "    # PRINT RESULTS\n",
    "    # ==================================================\n",
    "    print(f\"RF Accuracy       : {acc_rf:.2f}%\")\n",
    "    print(f\"XGB Accuracy      : {acc_xgb:.2f}%\")\n",
    "    print(f\"Ensemble Accuracy : {best_acc:.2f}% (alpha={best_alpha})\")\n",
    "    print(f\"âœ… Selected Model  : {best_model}\")\n",
    "\n",
    "    print(\"\\n--- FINAL METRICS ---\")\n",
    "    print(f\"Accuracy  : {acc:.2f}%\")\n",
    "    print(f\"Precision : {prec:.2f}%\")\n",
    "    print(f\"Recall    : {rec:.2f}%\")\n",
    "    print(f\"F1-score  : {f1:.2f}%\")\n",
    "    print(f\"ROC-AUC   : {roc_auc:.2f}%\" if roc_auc else \"ROC-AUC : Not defined\")\n",
    "    print(f\"MAE       : {mae:.4f}\")\n",
    "    print(f\"MSE       : {mse:.4f}\")\n",
    "    print(f\"RMSE      : {rmse:.4f}\")\n",
    "\n",
    "    final_summary[label] = {\n",
    "        \"Best Model\": best_model,\n",
    "        \"Accuracy\": acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "954c8a90-a472-4070-a513-cc2932e3231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ FINAL SUMMARY (Fault Line 1_39)\n",
      "============================================================\n",
      "B4              â†’ Random Forest   | Accuracy = 100.00%\n",
      "B1              â†’ Random Forest   | Accuracy = 100.00%\n",
      "\n",
      "âœ… PROCESS COMPLETED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# FINAL SUMMARY\n",
    "# ==================================================\n",
    "print(\"\\nðŸŽ¯ FINAL SUMMARY (Fault Line 1_39)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for lbl, res in final_summary.items():\n",
    "    print(f\"{lbl:15s} â†’ {res['Best Model']:15s} | Accuracy = {res['Accuracy']:.2f}%\")\n",
    "\n",
    "print(\"\\nâœ… PROCESS COMPLETED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca5a2f6a-905c-4a96-9ff5-cb26cd32dea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution After Filtering:\n",
      "\n",
      "Fault Location\n",
      "Fault Location\n",
      "1     2002\n",
      "99    2002\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Primary\n",
      "Primary\n",
      "R2     2002\n",
      "R36    2002\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "CCT\n",
      "CCT\n",
      "2.288    2002\n",
      "2.432    2002\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "B1\n",
      "B1\n",
      "R1     2002\n",
      "R48    2002\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "B4\n",
      "B4\n",
      "No    4004\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClass Distribution After Filtering:\\n\")\n",
    "for col in [\"Fault Location\", \"Primary\", \"CCT\", \"B1\", \"B4\"]:\n",
    "    print(col)\n",
    "    print(df[col].value_counts())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57431e3a-b9a9-4fe1-a7d1-99c5417bab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape: (135136, 24)\n",
      "Filtered Dataset Shape (Only 1_39): (4004, 24)\n",
      "Labels being used: ['Fault Location', 'Primary', 'CCT', 'B1']\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing Label: Fault Location\n",
      "============================================================\n",
      "RF Accuracy       : 99.70%\n",
      "XGB Accuracy      : 99.70%\n",
      "Ensemble Accuracy : 99.70% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 99.70%\n",
      "Precision : 99.70%\n",
      "Recall    : 99.70%\n",
      "F1-score  : 99.70%\n",
      "ROC-AUC   : 100.00%\n",
      "MAE       : 0.0030\n",
      "RMSE      : 0.0547\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing Label: Primary\n",
      "============================================================\n",
      "RF Accuracy       : 100.00%\n",
      "XGB Accuracy      : 100.00%\n",
      "Ensemble Accuracy : 100.00% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 100.00%\n",
      "Precision : 100.00%\n",
      "Recall    : 100.00%\n",
      "F1-score  : 100.00%\n",
      "ROC-AUC   : 100.00%\n",
      "MAE       : 0.0000\n",
      "RMSE      : 0.0000\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing Label: CCT\n",
      "============================================================\n",
      "RF Accuracy       : 99.90%\n",
      "XGB Accuracy      : 99.90%\n",
      "Ensemble Accuracy : 99.90% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 99.90%\n",
      "Precision : 99.90%\n",
      "Recall    : 99.90%\n",
      "F1-score  : 99.90%\n",
      "ROC-AUC   : 100.00%\n",
      "MAE       : 0.0010\n",
      "RMSE      : 0.0316\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing Label: B1\n",
      "============================================================\n",
      "RF Accuracy       : 100.00%\n",
      "XGB Accuracy      : 100.00%\n",
      "Ensemble Accuracy : 100.00% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 100.00%\n",
      "Precision : 100.00%\n",
      "Recall    : 100.00%\n",
      "F1-score  : 100.00%\n",
      "ROC-AUC   : 100.00%\n",
      "MAE       : 0.0000\n",
      "RMSE      : 0.0000\n",
      "\n",
      "ðŸŽ¯ FINAL SUMMARY (Fault Line 1_39)\n",
      "============================================================\n",
      "Fault Location  â†’ Random Forest   | Accuracy = 99.70%\n",
      "Primary         â†’ Random Forest   | Accuracy = 100.00%\n",
      "CCT             â†’ Random Forest   | Accuracy = 99.90%\n",
      "B1              â†’ Random Forest   | Accuracy = 100.00%\n",
      "\n",
      "âœ… PROCESS COMPLETED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# 0. IMPORT LIBRARIES\n",
    "# ==================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 1. LOAD DATASET\n",
    "# ==================================================\n",
    "file_path = r\"E:\\WOU_BITS INTERN\\39 BUS SYSTEM\\39 BUS SYSTEM FAULT.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Original Dataset Shape:\", df.shape)\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 2. FILTER ONLY FAULT LINE 1_39\n",
    "# ==================================================\n",
    "df = df[df[\"Fault Line\"] == \"1_39\"].copy()\n",
    "\n",
    "print(\"Filtered Dataset Shape (Only 1_39):\", df.shape)\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 3. DEFINE FEATURES AND LABELS\n",
    "# ==================================================\n",
    "FEATURES = [\n",
    "    \"Phase Voltage A/Terminal in kV\",\n",
    "    \"Phase Voltage B/Terminal in kV\",\n",
    "    \"Phase Voltage C/Terminal in kV\",\n",
    "    \"Phase Current A/Terminal in kA\",\n",
    "    \"Phase Current B/Terminal in kA\",\n",
    "    \"Phase Current C/Terminal in kA\",\n",
    "    \"Terminal/Bus\"\n",
    "]\n",
    "\n",
    "# ðŸ”¥ ONLY required labels (NO B4)\n",
    "LABELS = [\n",
    "    \"Fault Location\",\n",
    "    \"Primary\",\n",
    "    \"CCT\",\n",
    "    \"B1\"\n",
    "]\n",
    "\n",
    "print(\"Labels being used:\", LABELS)\n",
    "\n",
    "X = df[FEATURES]\n",
    "\n",
    "# ==================================================\n",
    "# 4. FEATURE SCALING\n",
    "# ==================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "final_summary = {}\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 5. LOOP THROUGH EACH LABEL\n",
    "# ==================================================\n",
    "for label in LABELS:\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"ðŸŽ¯ Processing Label: {label}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Skip if only one class\n",
    "    if df[label].nunique() < 2:\n",
    "        print(f\"âŒ {label} skipped â€” only one class present\")\n",
    "        continue\n",
    "\n",
    "    # Encode target\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[label])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y,\n",
    "        test_size=0.25,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # RANDOM FOREST\n",
    "    # ==================================================\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    rf_prob = rf.predict_proba(X_test)\n",
    "\n",
    "    acc_rf = accuracy_score(y_test, rf_pred) * 100\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # XGBOOST (Binary Safe Version)\n",
    "    # ==================================================\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    xgb_prob = xgb.predict_proba(X_test)\n",
    "\n",
    "    acc_xgb = accuracy_score(y_test, xgb_pred) * 100\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # ENSEMBLE (Soft Voting)\n",
    "    # ==================================================\n",
    "    best_alpha = 0\n",
    "    best_acc = 0\n",
    "    best_pred = None\n",
    "    best_prob = None\n",
    "\n",
    "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
    "        ens_prob = alpha * rf_prob + (1 - alpha) * xgb_prob\n",
    "        ens_pred = np.argmax(ens_prob, axis=1)\n",
    "        acc = accuracy_score(y_test, ens_pred) * 100\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_alpha = alpha\n",
    "            best_pred = ens_pred\n",
    "            best_prob = ens_prob\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # MODEL SELECTION\n",
    "    # ==================================================\n",
    "    scores = {\n",
    "        \"Random Forest\": acc_rf,\n",
    "        \"XGBoost\": acc_xgb,\n",
    "        \"Ensemble\": best_acc\n",
    "    }\n",
    "\n",
    "    best_model = max(scores, key=scores.get)\n",
    "\n",
    "    if best_model == \"Random Forest\":\n",
    "        y_pred = rf_pred\n",
    "        y_prob = rf_prob\n",
    "        final_acc = acc_rf\n",
    "    elif best_model == \"XGBoost\":\n",
    "        y_pred = xgb_pred\n",
    "        y_prob = xgb_prob\n",
    "        final_acc = acc_xgb\n",
    "    else:\n",
    "        y_pred = best_pred\n",
    "        y_prob = best_prob\n",
    "        final_acc = best_acc\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # FINAL METRICS\n",
    "    # ==================================================\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # For binary ROC-AUC\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_test, y_prob[:, 1]) * 100\n",
    "    except:\n",
    "        roc_auc = None\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # PRINT RESULTS\n",
    "    # ==================================================\n",
    "    print(f\"RF Accuracy       : {acc_rf:.2f}%\")\n",
    "    print(f\"XGB Accuracy      : {acc_xgb:.2f}%\")\n",
    "    print(f\"Ensemble Accuracy : {best_acc:.2f}% (alpha={best_alpha})\")\n",
    "    print(f\"âœ… Selected Model  : {best_model}\")\n",
    "\n",
    "    print(\"\\n--- FINAL METRICS ---\")\n",
    "    print(f\"Accuracy  : {final_acc:.2f}%\")\n",
    "    print(f\"Precision : {precision:.2f}%\")\n",
    "    print(f\"Recall    : {recall:.2f}%\")\n",
    "    print(f\"F1-score  : {f1:.2f}%\")\n",
    "    print(f\"ROC-AUC   : {roc_auc:.2f}%\" if roc_auc else \"ROC-AUC : Not defined\")\n",
    "    print(f\"MAE       : {mae:.4f}\")\n",
    "    print(f\"RMSE      : {rmse:.4f}\")\n",
    "\n",
    "    final_summary[label] = {\n",
    "        \"Best Model\": best_model,\n",
    "        \"Accuracy\": final_acc\n",
    "    }\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# FINAL SUMMARY\n",
    "# ==================================================\n",
    "print(\"\\nðŸŽ¯ FINAL SUMMARY (Fault Line 1_39)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for lbl, res in final_summary.items():\n",
    "    print(f\"{lbl:15s} â†’ {res['Best Model']:15s} | Accuracy = {res['Accuracy']:.2f}%\")\n",
    "\n",
    "print(\"\\nâœ… PROCESS COMPLETED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20d9f659-44fc-466e-bbb8-6fd79abc3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape: (135136, 24)\n",
      "Filtered Dataset Shape (Only 1_39): (4004, 24)\n",
      "Labels being used: ['Fault Location', 'Primary', 'CCT', 'B1']\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing Label: Fault Location\n",
      "============================================================\n",
      "RF Accuracy       : 99.70%\n",
      "XGB Accuracy      : 99.70%\n",
      "Ensemble Accuracy : 99.70% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 99.70%\n",
      "Precision : 99.70%\n",
      "Recall    : 99.70%\n",
      "F1-score  : 99.70%\n",
      "ROC-AUC   : 100.00%\n",
      "MAE       : 0.0030\n",
      "RMSE      : 0.0547\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing Label: Primary\n",
      "============================================================\n",
      "RF Accuracy       : 100.00%\n",
      "XGB Accuracy      : 100.00%\n",
      "Ensemble Accuracy : 100.00% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 100.00%\n",
      "Precision : 100.00%\n",
      "Recall    : 100.00%\n",
      "F1-score  : 100.00%\n",
      "ROC-AUC   : 100.00%\n",
      "MAE       : 0.0000\n",
      "RMSE      : 0.0000\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing Label: CCT\n",
      "============================================================\n",
      "RF Accuracy       : 99.90%\n",
      "XGB Accuracy      : 99.90%\n",
      "Ensemble Accuracy : 99.90% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 99.90%\n",
      "Precision : 99.90%\n",
      "Recall    : 99.90%\n",
      "F1-score  : 99.90%\n",
      "ROC-AUC   : 100.00%\n",
      "MAE       : 0.0010\n",
      "RMSE      : 0.0316\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Processing Label: B1\n",
      "============================================================\n",
      "RF Accuracy       : 100.00%\n",
      "XGB Accuracy      : 100.00%\n",
      "Ensemble Accuracy : 100.00% (alpha=0.1)\n",
      "âœ… Selected Model  : Random Forest\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "Accuracy  : 100.00%\n",
      "Precision : 100.00%\n",
      "Recall    : 100.00%\n",
      "F1-score  : 100.00%\n",
      "ROC-AUC   : 100.00%\n",
      "MAE       : 0.0000\n",
      "RMSE      : 0.0000\n",
      "\n",
      "ðŸŽ¯ FINAL SUMMARY (Fault Line 1_39)\n",
      "============================================================\n",
      "Fault Location  â†’ Random Forest   | Accuracy = 99.70%\n",
      "Primary         â†’ Random Forest   | Accuracy = 100.00%\n",
      "CCT             â†’ Random Forest   | Accuracy = 99.90%\n",
      "B1              â†’ Random Forest   | Accuracy = 100.00%\n",
      "\n",
      "âœ… PROCESS COMPLETED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# 0. IMPORT LIBRARIES\n",
    "# ==================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 1. LOAD DATASET\n",
    "# ==================================================\n",
    "file_path = r\"E:\\WOU_BITS INTERN\\39 BUS SYSTEM\\39 BUS SYSTEM FAULT.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Original Dataset Shape:\", df.shape)\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 2. FILTER ONLY FAULT LINE 1_39\n",
    "# ==================================================\n",
    "df = df[df[\"Fault Line\"] == \"1_39\"].copy()\n",
    "\n",
    "print(\"Filtered Dataset Shape (Only 1_39):\", df.shape)\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 3. DEFINE FEATURES AND LABELS\n",
    "# ==================================================\n",
    "FEATURES = [\n",
    "    \"Phase Voltage A/Terminal in kV\",\n",
    "    \"Phase Voltage B/Terminal in kV\",\n",
    "    \"Phase Voltage C/Terminal in kV\",\n",
    "    \"Phase Current A/Terminal in kA\",\n",
    "    \"Phase Current B/Terminal in kA\",\n",
    "    \"Phase Current C/Terminal in kA\",\n",
    "    \"Terminal/Bus\"\n",
    "]\n",
    "\n",
    "# ðŸ”¥ ONLY required labels (NO B4)\n",
    "LABELS = [\n",
    "    \"Fault Location\",\n",
    "    \"Primary\",\n",
    "    \"CCT\",\n",
    "    \"B1\"\n",
    "]\n",
    "\n",
    "print(\"Labels being used:\", LABELS)\n",
    "\n",
    "X = df[FEATURES]\n",
    "\n",
    "# ==================================================\n",
    "# 4. FEATURE SCALING\n",
    "# ==================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "final_summary = {}\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 5. LOOP THROUGH EACH LABEL\n",
    "# ==================================================\n",
    "for label in LABELS:\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"ðŸŽ¯ Processing Label: {label}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Skip if only one class\n",
    "    if df[label].nunique() < 2:\n",
    "        print(f\"âŒ {label} skipped â€” only one class present\")\n",
    "        continue\n",
    "\n",
    "    # Encode target\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[label])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y,\n",
    "        test_size=0.25,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # RANDOM FOREST\n",
    "    # ==================================================\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=250,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    rf_prob = rf.predict_proba(X_test)\n",
    "\n",
    "    acc_rf = accuracy_score(y_test, rf_pred) * 100\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # XGBOOST (Binary Safe Version)\n",
    "    # ==================================================\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=350,\n",
    "        learning_rate=0.07,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    xgb_prob = xgb.predict_proba(X_test)\n",
    "\n",
    "    acc_xgb = accuracy_score(y_test, xgb_pred) * 100\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # ENSEMBLE (Soft Voting)\n",
    "    # ==================================================\n",
    "    best_alpha = 0\n",
    "    best_acc = 0\n",
    "    best_pred = None\n",
    "    best_prob = None\n",
    "\n",
    "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
    "        ens_prob = alpha * rf_prob + (1 - alpha) * xgb_prob\n",
    "        ens_pred = np.argmax(ens_prob, axis=1)\n",
    "        acc = accuracy_score(y_test, ens_pred) * 100\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_alpha = alpha\n",
    "            best_pred = ens_pred\n",
    "            best_prob = ens_prob\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # MODEL SELECTION\n",
    "    # ==================================================\n",
    "    scores = {\n",
    "        \"Random Forest\": acc_rf,\n",
    "        \"XGBoost\": acc_xgb,\n",
    "        \"Ensemble\": best_acc\n",
    "    }\n",
    "\n",
    "    best_model = max(scores, key=scores.get)\n",
    "\n",
    "    if best_model == \"Random Forest\":\n",
    "        y_pred = rf_pred\n",
    "        y_prob = rf_prob\n",
    "        final_acc = acc_rf\n",
    "    elif best_model == \"XGBoost\":\n",
    "        y_pred = xgb_pred\n",
    "        y_prob = xgb_prob\n",
    "        final_acc = acc_xgb\n",
    "    else:\n",
    "        y_pred = best_pred\n",
    "        y_prob = best_prob\n",
    "        final_acc = best_acc\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # FINAL METRICS\n",
    "    # ==================================================\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\") * 100\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # For binary ROC-AUC\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_test, y_prob[:, 1]) * 100\n",
    "    except:\n",
    "        roc_auc = None\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # PRINT RESULTS\n",
    "    # ==================================================\n",
    "    print(f\"RF Accuracy       : {acc_rf:.2f}%\")\n",
    "    print(f\"XGB Accuracy      : {acc_xgb:.2f}%\")\n",
    "    print(f\"Ensemble Accuracy : {best_acc:.2f}% (alpha={best_alpha})\")\n",
    "    print(f\"âœ… Selected Model  : {best_model}\")\n",
    "\n",
    "    print(\"\\n--- FINAL METRICS ---\")\n",
    "    print(f\"Accuracy  : {final_acc:.2f}%\")\n",
    "    print(f\"Precision : {precision:.2f}%\")\n",
    "    print(f\"Recall    : {recall:.2f}%\")\n",
    "    print(f\"F1-score  : {f1:.2f}%\")\n",
    "    print(f\"ROC-AUC   : {roc_auc:.2f}%\" if roc_auc else \"ROC-AUC : Not defined\")\n",
    "    print(f\"MAE       : {mae:.4f}\")\n",
    "    print(f\"RMSE      : {rmse:.4f}\")\n",
    "\n",
    "    final_summary[label] = {\n",
    "        \"Best Model\": best_model,\n",
    "        \"Accuracy\": final_acc\n",
    "    }\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# FINAL SUMMARY\n",
    "# ==================================================\n",
    "print(\"\\nðŸŽ¯ FINAL SUMMARY (Fault Line 1_39)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for lbl, res in final_summary.items():\n",
    "    print(f\"{lbl:15s} â†’ {res['Best Model']:15s} | Accuracy = {res['Accuracy']:.2f}%\")\n",
    "\n",
    "print(\"\\nâœ… PROCESS COMPLETED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63d853-d518-414c-992e-46b846317f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
